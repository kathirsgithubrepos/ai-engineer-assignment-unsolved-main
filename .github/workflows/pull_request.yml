name: Pull Request Validation

on:
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read
  pull-requests: write

jobs:
  evaluate:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies (PR)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ----- Run solution on PR branch -----
      - name: Run solution (PR)
        run: |
          python scripts/solution.py \
            --employees_path data/employees.csv \
            --connections_path data/connections.csv \
            --output_path pr_submission.csv

      - name: Evaluate PR accuracy
        id: eval_pr
        run: |
          python dependencies/evaluate.py pr_submission.csv data/ground_truth_managers.csv
          PR=$(cat accuracy.txt | tr -d '%')
          echo "pr_score=$PR" >> "$GITHUB_OUTPUT"

      # ----- Run solution on main branch in a separate directory -----
      - name: Checkout main into ./main_ref
        uses: actions/checkout@v4
        with:
          ref: main
          path: main_ref

      - name: Install dependencies (main)
        run: |
          pip install -r main_ref/requirements.txt

      - name: Run solution (main)
        working-directory: main_ref
        run: |
          python scripts/solution.py \
            --employees_path data/employees.csv \
            --connections_path data/connections.csv \
            --output_path main_submission.csv

      - name: Evaluate main accuracy
        id: eval_main
        working-directory: main_ref
        run: |
          python dependencies/evaluate.py main_submission.csv data/ground_truth_managers.csv
          MAIN=$(cat accuracy.txt | tr -d '%')
          echo "main_score=$MAIN" >> "$GITHUB_OUTPUT"

      # ----- Comment results on the PR -----
      - name: Comment PR results
        uses: actions/github-script@v7
        env:
          PR_SCORE: ${{ steps.eval_pr.outputs.pr_score }}
          MAIN_SCORE: ${{ steps.eval_main.outputs.main_score }}
        with:
          github-token: ${{ secrets.GH_TOKEN }}
          script: |
            const prScore = parseFloat(process.env.PR_SCORE);
            const mainScore = parseFloat(process.env.MAIN_SCORE);
            const verdict = prScore > mainScore
              ? "‚úîÔ∏è Improved"
              : (prScore === mainScore ? "‚ûñ No change" : "‚ùå Regression");

            const lines = [
              "### ü§ñ Automated Evaluation",
              "",
              "| Metric | Main | PR |",
              "|------:|----:|---:|",
              `| Accuracy | ${mainScore}% | ${prScore}% |`,
              "",
              `**Verdict:** ${verdict}`
            ];
            const body = lines.join("\n");

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body
            });



